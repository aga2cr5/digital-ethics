# Privacy and Surveillance as Government and Private Sector Assets

## Introduction
In the digital age, the increasing pace of scientific advances brings us novel challenges constantly. This constant shift to more technologically advanced society is supposed to be easier, better and safer place for us to live and prosper but while convenience and interconnectedness are embraced by tech enthusiasts the shady and predatory side of the story is often overlooked.

In the past privacy has often been predominantly linked to physical spaces and interpersonal relationships. However, the current digital landscape has in many ways shaped and blurred the lines and meaning of privacy for good. This change has brought a need for necessitating new framework for rules and regulations which would better suit to protect us from various organizations, be it private companies or governments.

During the past decade smartphone usage has exponentially increased. Not only the amount of people having smartphones but also the average time been spent on these devices and the platforms they facilitate. (Flynn, 2023) This usage of digital devices is creating unprecedented amounts of data which is used to track people on a massive scale. Although, smartphones play a large role in the consumer data collection, it is the combined effort of several data sources which enable companies and governments to build models to predict citizen or consumer behavior. This in turn can, and often is, being used to profile people in a way that is not in their best interest.

A significant part of the privacy issue is lack of knowledge and understanding. Topic related to data privacy, security and protection can be rather complicated. When an average consumer is eager to use a new application, they just downloaded they are quick to click the “agree” button on the privacy notice without even thinking of reading it. This might be due to application stores evoking feelings of trust. It could also be that consumers just find it too time consuming to go through 80 pages of legal text.

The change is not a new and sudden but has rather been happening slowly as large digital platforms, such as Google, Facebook, Twitter, etc., have gained the market capital in massive data pools consisting of user information and their behavior. This, of course, is just a part of the story. Issues with privacy and surveillance are tightly tied to governments whose interest it often is to control certain groups of people. Sometimes this is for a reason but often the real reasons lie in discriminatory policies. This kind of government behavior can be seen in, for example, China, against Uyghurs in Xinjiang, and in Israel, against Palestinians.

In many cases the surveillance does not have such obvious consequences. For example, a government would probably not build a facial recognition system like China as a first phase of their surveillance campaign. It is more logical to first install vast number of CCTV cameras around the areas which are wished to be under surveillance. Then in later phases they introduce a new facial recognition system. How do the citizens of a country allow this? Often, they don’t but in the times of uncertainties, such as Covid-19 pandemic and Russia’s war on Ukraine, people are more willing to opt for safety than privacy. These are the times when normally unwanted changes and policies get hammered in and once those have been cemented it is hard to get rid of them. Therefore, especially during turbulent times societies must be more critical of the changes made to protect them than usually.

Moreover, right to and access to privacy is, and should, be important for democracy and individuals. The lack of privacy and increasing surveillance pose several important ethical dilemmas, such as, who has a right to privacy, what is privacy and how much privacy should an individual have? These fundamental questions are the important in so many levels that they deserve deeper inspection.

## Ethical dimensions of Data Collection and Storage
When large companies, such as Google and Meta (formerly known as Facebook), collect vast amounts of data from their users they get flighty rich. Their motivation is money. The little they care for their customers privacy is because regulations mandate them. After all, making creating value and capital for their investors is the sole purpose of the companies. Is it then a good idea to have large companies hold so much information of peoples everything? Of course, we have all agreed to this by signing the privacy notices and given our consents to this but what does “giving permission” mean and how much value does it hold if we do not have a choice, the choice is a bad one or we just do not understand what we are signing up for?

It is an interesting thing to wonder how many people have read the “Terms and conditions” (TAC) of any given service? There will always be a few journalists, or people with too much time on their hands, to read these documents through but for the most part we tick the boxes without giving it a second thought. Is this equal to saying, “I consent”? Legally it is but should it be so? One could argue that there is a great distinction to be made here. Many times, we might lack the choice not to agree on the TAC since some of these companies and platforms have almost monopoly status. If you are not on Facebook, you might miss on important events which are only announced there. Some public companies might only offer customer service through Facebook Messenger application in which case you either accept the TAC or do not get customer service.

In many cases consumers are not even aware or simply do not understand what they are agreeing to. A prime example is a Russian application called FaceApp. This application hit the news in the 2019 after a user read the terms and conditions and noticed that users were giving their consent to use their photos and data forever to whatever purposes the company wanted. (Staff, 2019; Mekuli, 2023) It can be assumed that most people would not have been fine with this level of data collection. This demonstrates well that giving consent does not always work as it is intended when it is just a box to tick.

## Data Usage and Privacy Concerns
Data collection itself is not necessarily nefarious. It is what comes after it. When organizations, be it private companies, governments, etc., enrich data to information about subjects or groups this in when data can become a weapon. It might leave consumers in situations where they do not have equal opportunity to get loans from banks because how the bank’s credibility systems assess the customer. Some shops could limit the customers let into their stores based on the likelihood of them stealing products. How is this a bad thing then? If a shop owner can prevent shoplifting, then how is that a bad thing? The problem lies in unjust profiling base on, for example, ethnicity or mental issues. A shop owner might not allow people of color (POC) in their shop because the model to make the decisions could have been trained with biased data sets. A person might not be able to get a loan to buy a house because they have suffered from a depression in the past. In other words, information enriched from data may aid in decision making but at the same time it may harm the information subjects.

According to documentary Coded Bias (2020), many of the present-day machine learning models used to do automated decision making are heavily biased against POC. The training data used in these models has withheld the racist structures imbedded in our societies. These structures have then passed along the data to the machine learning models. For example, detectors in hand sanitizer dispensers have been, in some instances, shown not to response to darker skin hands (Goethe, 2019). Is it the soap dispenser who is then racist or is it the data?

## Regulating Data Practices
As companies’ primary goal is to generate profit to its owners the only reliable way to ensure decent privacy practices is to enforce regulation. In some field, regulation has worked well. It can be utilized in, for example, various industries to provide better working conditions for employees and to make sure manufactured products fit certain safety standards. Therefore, regulation usually goes hand in hand with standardization.

In the technology industry, regulation has happened and is developed continously. The challenge lies in the fast pace of development. This poses massive challenges to legislative parties passing regulation on data collection when in a year new challenge has already appeared. New companies entering the market trying to find loopholes to exploit and make quick money seems never ending. This has been seen with Web3 companies spawning around the blockchain hype at accelerating speed (White, 2023). 

In the European Union (EU), the General Data Protection Regulation (GDRP) was passed in 2018. This regulation is claimed to be “the toughest privacy and security law in the world”. The las imposes harsh fines to companies or organizations violating it. The core idea of the GRPD is that no information should be collected from customers which is not needed for the service to operate. Collected data should be deleted after certain time when it is not necessary to store anymore. Customers should have a right to be “forgotten” which means they should have right to ask a register holder to remove all data linked to them. Location of the data is also important part of the GDPR. All collected data on European legal persons should remain inside EU borders meaning it should not be stored in a data warehouse in America. (European Union, 2018)

## Surveillance and Privacy in the Digital Age
Surveillance can be justified with security. As discussed earlier, in turbulent times people might be more willing to give a portion of their privacy in exchange of security. According to news article from Helsingin Sanomat (Palkoaho, 2022), Finland might be facing increasing amounts of gang related crimes. These types of news are excellent in driving people’s attitudes to being more positive about increasing surveillance. During the same year, Finnish police forces are trying to extend their permissions to conduct wiretapping (Reinboth, 2022). This is still just a proposal, but it clearly demonstrates when a good time is to tighten the grip from the society with increased surveillance.

In several countries though, public response on smart closed-circuit television (CCTV) systems has not been only negative. According to a study by Kostka et al. (2021), in countries, such as the United Kingdom, China, Germany and the United States, public attitudes towards facial recognition technologies (FRT) are not always seen just as negative but also as “notions of convenience and improved security”. It is still unclear how public attitude might change on FRT when it is more widely implemented.

Even though public may sometimes have positive views and experiences of surveillance that is not the case always. As western governments, such as the United States, have tighten their grips on the public in surveillance wise we have gradually lost our individual privacy (Grabiner, 2012). The National Security Agency (NSA) leaks by Edward Snowden in 2013 revealed the extent the government was spying on people. According to Rieder (2018), the public has a distorted image on privacy. While private sector companies have added encryption to their user data, they have allegedly opened backdoors to governments in secrecy (Rieder, 2018). This highlights the change where talk about individual privacy has gone from public to underground. Currently there is a lot that we cannot see because it is classified.

## Conclusion and Possible Solutions
The present-day world is looking increasingly like the one proposed by George Orwell’s novel 1984. We live in ever expanding surveillance and data collection landscape. Surveillance and privacy are dividing topic. On the other hand, human should have rights for privacy but on the other hand there is public safety. Therefore, the real question is how to balance this. Although, people generally trust governments more than the private sector regarding FRT the public should remain critical of the government’s actions (Kostka et al., 2021). People often tend to overlook discrimination if it is not directed to themselves. This is why we should be aware of changing government policies because even though it might not affect us directly it could very well be affecting our friends, family or co-workers.

As large technology companies are tightening their monopoly of the market, we should also be creating new regulation to control their actions. This can fight against companies with more money than some countries seem like a fight between David and Goliath, but it should not be a reason to back off. Important way of combatting privacy infringements and increasing surveillance is to raise public awareness on the topic. Many, especially elderly people, do not have the same resources and understanding of digital world in the same way as younger generations. This greatly limits their ability to be a part of the decision making. In many cases even the younger generations are not knowledgeable of the topics to form rational decisions. This is why education system in countries should have a greater role of teaching privacy related topics to next generations.




## Note
The author of this paper states that generative language model, ChatGPT (GPT-3.5), has been used to generate a rough structure for this essay. The language model was deemed acceptable to be used as an aid in the creation of the structure since all the content written in the paragraphs and the section titles are still original work of the author.

## References
Coded Bias (2020) Directed by Shalini Kantayya, [Documentary], Netflix.

European Union (2018) GDPR Archives, GDPR.eu. Available at: https://gdpr.eu/tag/gdpr/ (Accessed: 23 June 2023).

Flynn, J. (2023) 20 vital smartphone usage statistics [2023]: Facts, data, and trends on mobile use in the U.S., Zippia. Available at: https://www.zippia.com/advice/smartphone-usage-statistics/ (Accessed: 23 June 2023).

Goethe, T. (2019) Bigotry encoded: Racial bias in technology, BIGOTRY ENCODED: RACIAL BIAS IN TECHNOLOGY. Available at: https://reporter.rit.edu/tech/bigotry-encoded-racial-bias-technology (Accessed: 23 June 2023).

Grabiner, G. (2012), "Commentary: Government and Market Surveillance, Emergence of Mass Political Society, and the Need for Progressive Social Change", Social Justice, vol. 39, no. 4, pp. 115-125,128.

Kostka, G. et al. (2021) Between security and convenience: Facial recognition technology in the eyes of citizens in China, Germany, the United Kingdom, and the United States. Public understanding of science (Bristol, England). [Online] 30 (6), 671–690.

Mekuli, A. (2023) How invasive are face transforming apps – a privacy disaster waiting to happen?, VPNOverview.com. Available at: https://vpnoverview.com/privacy/apps/face-transforming-apps/ (Accessed: 22 June 2023)

Palkoaho, M. (2022) Katujengit: Entinen Jengirikollinen Pelkää Suomen Luisuvan Ruotsiakin Pahempaan tilanteeseen, Helsingin Sanomat. Available at: https://www.hs.fi/kaupunki/art-2000009119304.html (Accessed: 23 June 2023).

Reinboth, S. (2022) Pakkokeinot: Poliisi on Saamassa Lisäoikeuksia Puhelinkuunteluun, Helsingin Sanomat. Available at: https://www.hs.fi/kotimaa/art-2000009146848.html (Accessed: 23 June 2023).

Rider, K. (2018) The privacy paradox: how market privacy facilitates government surveillance. Information, communication & society. [Online] 21 (10), 1369–1385.

Staff, S. (2019) Scared of FaceApp stealing your data? it’s not the creepiest part of their fine print, ScienceAlert. Available at: https://www.sciencealert.com/scared-of-faceapp-stealing-your-data-it-s-not-the-creepiest-part-of-their-fine-print (Accessed: 22 June 2023).

White, M. (2023) Web3 is going just great, Illustration: A sad-looking Bored Ape Yacht Club NFT monkey looks at a world engulfed in flames. Available at: https://web3isgoinggreat.com/ (Accessed: 23 June 2023).
