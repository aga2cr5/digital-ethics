# Digital Ethics

As with any field, computer and digital world also requires ethics to guide it and its development into right tracks. For this purpose there is digital ethics. This sub-branch of moral philosophy is most closely related to applied ethics. To better understand what applied ethics means a quick overview of moral philosophy should conducted first.

Moral philosophy can be divided into three different branches; metaethics, normative moral theory and applied ethics. These focus on distinctive aspects of ethical inquiry. Metaethics is concerned with the fundamental questions about the nature of ethical thought and language, and aims to provide a deeper understanding of the meaning and justification of moral claims. Normative moral theory, on the other hand, is concerned with the formulation of general moral principles and theories that guide ethical decision-making. It aims to develop a systematic and coherent framework for understanding and evaluating moral choices. Applied ethics is the application of normative ethical theories to specific practical moral problems. It is concerned with examining real-world ethical issues and providing guidance on how to act in morally complex situations. (OpenAI, 2023; Copp, 2007)

The field of computer ethics, as the technological advances in generative artificial intelligence (AI) keep accelerating, is more topical than ever before. To understand the current state of the discussion on the moral dilemmas of the field, we must also be familiar with how the field of computer ethics was formed.

For around 50 years, computer ethics has been an important part of the policy making around computers and digital world. It was created for shaping rules, guidelines and policies on how computers should be used in an ethical matter. Some of the questions computer ethics tries to answer are, according to Moor (1985), what parts of a computer program can be owned? Can an algorithm be somebody's intellectual property? What if we can not know exactly what the computer program does or how it functions? Can we trust computers to make important decisions which have lives depending on them? These questions raise serious concerns about how we should regulate computer technology. When a company creates a computer program or an algorithm more often than not the motivation behind it is monetary gain. This creates a high potential for misuse of technology. To prevent this kind of, in some cases, destructive technology it is important to have discussions about the digital ethics of computers. These discussions give foundations for new policies which in term help to regulate the field in a fair and safe way.

Since the concept of computer ethics arose around 50 years ago, many of the things discussed even then are still topical to this day. In the paper about computer ethics by Moor (1985), topics, such as, computers and elections, how computer affects studying, operating weapons with computers and problematic nature of programmed biases in algorithms, are discussed. Today these very same topics constantly circulate in media and public discussion. This really emphasizes how morally difficult some of these problems are. Simply put, they do not have simple answers. Where as one might say that computers are not human and therefore sometimes make too "cold" decision, sometimes this is indeed what is needed. Often it is thought that computers eradicate human error but on the other hand if computer programs are created by humans, are the human errors not hard coded in the program?

More recent ethical dilemma arose around 2010 when discussion about issues with privacy started to be more topical. With the rise of social medias and massive data collection operations the issue of who is entitled and has access to privacy emerges. Currently European Union (2022) is tightening regulation around data of EU citizens and corporations. This is a major step into the right direction of regulating the giants of digital world, such as Google, Facebook, Twitter, etc. This regulation is important because, for example, large social media companies have been collecting data from their user which in term is being sold to other companies. Moreover, this data, when refined into information, can be used to control people in ways which may be discriminatory. One example of this could be to create algorithms or AI models which, with the aid of computer vision, decide if certain people should be let into shops. There are reports that in some cases people of color (POC) have been denied entry to shops because the computer program thought there was too high of a risk them stealing things.

Although the field of digital ethics is not new anymore it certainly could not be more topical today. As we see the ever accelerating race for creating ever more sophisticated AI, there is increasing demand on the discussion of the ethical dilemmas of it. Sadly technology often develops at more rapid pace than its ethics.

## References

Copp, D., 2007. Introduction: Metaethics and Normative Ethics.

European Union. (2022). Yleinen tietosuoja-asetus. Available at: <https://europa.eu/youreurope/business/dealing-with-customers/data-protection/data-protection-gdpr/index_fi.htm> (Accessed: 3 May 2023)

Moor, J.H., 1985. What is computer ethics?. Metaphilosophy, 16(4), pp.266-275.

OpenAI. (2023). ChatGPT (Mar 14 version) [Large language model]. <https://chat.openai.com/chat>

## Appendix

The author of this paper states that generative language model, ChatGPT, has been used to generate structure for the definitions of moral philosophy and its branches. The language model was deemed acceptable to be used as aid in the creation this part of this paper since the terms explained were fairly trivial in their nature.
